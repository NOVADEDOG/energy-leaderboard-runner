[
  {
    "prompt": "What is the capital city of Japan?",
    "completion": "The capital city of Japan is **Tokyo**.",
    "tokens_prompt": 75,
    "tokens_completion": 41,
    "duration_s": 1.726,
    "response_time_s": 1.726,
    "energy_wh_raw": 0.013205,
    "energy_wh_net": 0.013205,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q1",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A one‑word answer naming Japan’s capital (Tokyo).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Very short prompt and answer provide a baseline for minimal energy consumption.",
    "tags": [
      "energy-baseline",
      "short-context",
      "factual"
    ],
    "wh_per_1k_tokens": 0.113836,
    "energy_kwh_per_token": 1.14e-07,
    "g_co2": 0.004622
  },
  {
    "prompt": "Calculate 7 + 5.",
    "completion": "7 + 5 = 12.",
    "tokens_prompt": 74,
    "tokens_completion": 40,
    "duration_s": 0.934,
    "response_time_s": 0.934,
    "energy_wh_raw": 0.012367,
    "energy_wh_net": 0.012367,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q2",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A single number representing the sum (12).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Simple arithmetic with minimal computation and output length.",
    "tags": [
      "numeric",
      "low-compute",
      "energy-baseline"
    ],
    "wh_per_1k_tokens": 0.108482,
    "energy_kwh_per_token": 1.08e-07,
    "g_co2": 0.004328
  },
  {
    "prompt": "Name the largest planet in our solar system.",
    "completion": "The largest planet in our solar system is **Jupiter**.",
    "tokens_prompt": 76,
    "tokens_completion": 44,
    "duration_s": 1.03,
    "response_time_s": 1.03,
    "energy_wh_raw": 0.012562,
    "energy_wh_net": 0.012562,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q3",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The name of the largest planet (Jupiter).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short factual recall requiring little reasoning.",
    "tags": [
      "astronomy",
      "factual",
      "energy-baseline"
    ],
    "wh_per_1k_tokens": 0.104683,
    "energy_kwh_per_token": 1.05e-07,
    "g_co2": 0.004397
  },
  {
    "prompt": "What is the chemical symbol for water?",
    "completion": "The chemical formula (often referred to as the “symbol”) for water is **H₂O**.",
    "tokens_prompt": 75,
    "tokens_completion": 53,
    "duration_s": 1.197,
    "response_time_s": 1.197,
    "energy_wh_raw": 0.016147,
    "energy_wh_net": 0.016147,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q4",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The two‑letter chemical formula (H2O).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short chemical knowledge question; minimal output.",
    "tags": [
      "chemistry",
      "short-output",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.126148,
    "energy_kwh_per_token": 1.26e-07,
    "g_co2": 0.005651
  },
  {
    "prompt": "Who wrote the play ‘Romeo and Juliet’?",
    "completion": "“Romeo and Juliet” was written by **William Shakespeare**.",
    "tokens_prompt": 77,
    "tokens_completion": 52,
    "duration_s": 1.191,
    "response_time_s": 1.191,
    "energy_wh_raw": 0.016413,
    "energy_wh_net": 0.016413,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q5",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The author’s name (William Shakespeare).",
    "max_output_tokens_hint": 6,
    "energy_relevance": "Simple fact retrieval; low energy.",
    "tags": [
      "literature",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.127233,
    "energy_kwh_per_token": 1.27e-07,
    "g_co2": 0.005745
  },
  {
    "prompt": "In which year did humans first land on the Moon?",
    "completion": "Humans first set foot on the Moon in **1969**, during NASA’s Apollo 11 mission. The historic landing occurred on July 20, 1969.",
    "tokens_prompt": 78,
    "tokens_completion": 75,
    "duration_s": 1.637,
    "response_time_s": 1.637,
    "energy_wh_raw": 0.024842,
    "energy_wh_net": 0.024842,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q6",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A four‑digit year (1969).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short question with numeric answer; minimal compute.",
    "tags": [
      "history",
      "numeric",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.162366,
    "energy_kwh_per_token": 1.62e-07,
    "g_co2": 0.008695
  },
  {
    "prompt": "Which element has the atomic number 6?",
    "completion": "The element with atomic number 6 is **carbon (C)**.",
    "tokens_prompt": 76,
    "tokens_completion": 48,
    "duration_s": 1.118,
    "response_time_s": 1.118,
    "energy_wh_raw": 0.015814,
    "energy_wh_net": 0.015814,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q7",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The element’s name (Carbon).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Simple factual recall; low energy cost.",
    "tags": [
      "chemistry",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.127532,
    "energy_kwh_per_token": 1.28e-07,
    "g_co2": 0.005535
  },
  {
    "prompt": "What is the square root of 49?",
    "completion": "The principal (non‑negative) square root of 49 is **7**.\n\n(If you consider both roots of the equation \\(x^2 = 49\\), the solutions are \\(x = 7\\) and \\(x = -7\\).)",
    "tokens_prompt": 76,
    "tokens_completion": 99,
    "duration_s": 2.086,
    "response_time_s": 2.086,
    "energy_wh_raw": 0.029558,
    "energy_wh_net": 0.029558,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q8",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A single integer (7).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Basic arithmetic with one‑word output.",
    "tags": [
      "math",
      "numeric",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.168903,
    "energy_kwh_per_token": 1.69e-07,
    "g_co2": 0.010345
  },
  {
    "prompt": "How many continents are there on Earth?",
    "completion": "There are **seven** continents on Earth:\n\n1. **Africa**  \n2. **Antarctica**  \n3. **Asia**  \n4. **Europe**  \n5. **North America**  \n6. **South America**  \n7. **Australia** (sometimes referred to as Oceania when including the surrounding Pacific islands)\n\n*Note:* In some geographical models, Europe and Asia are combined into a single continent called **Eurasia**, and the Americas are sometimes combined as **America**, which would give a six‑ or five‑continent count. However, the most widely taught and accepted classification uses seven distinct continents.",
    "tokens_prompt": 75,
    "tokens_completion": 211,
    "duration_s": 4.256,
    "response_time_s": 4.256,
    "energy_wh_raw": 0.066581,
    "energy_wh_net": 0.066581,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q9",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A small integer (7).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Short factual query; minimal compute and output.",
    "tags": [
      "geography",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.232801,
    "energy_kwh_per_token": 2.33e-07,
    "g_co2": 0.023303
  },
  {
    "prompt": "When you mix red and blue paint, what color do you get?",
    "completion": "When you mix red and blue **paint** (which follows subtractive color mixing), you get a **purple** (often called violet) hue. The exact shade can vary depending on the specific pigments used—some reds lean toward orange and some blues lean toward green—so the resulting purple may be more reddish‑violet, bluish‑violet, or somewhere in between.",
    "tokens_prompt": 81,
    "tokens_completion": 136,
    "duration_s": 2.858,
    "response_time_s": 2.858,
    "energy_wh_raw": 0.044034,
    "energy_wh_net": 0.044034,
    "provider": "openai",
    "model": "gpt-oss-120b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low‑energy baseline by asking simple factual or arithmetic questions that require short, single‑sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q10",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The resulting secondary color (purple or violet).",
    "max_output_tokens_hint": 6,
    "energy_relevance": "Simple fact with one‑word answer to establish baseline energy usage.",
    "tags": [
      "color-mixing",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.202922,
    "energy_kwh_per_token": 2.03e-07,
    "g_co2": 0.015412
  }
]