[
  {
    "prompt": "What is the capital city of Japan?",
    "completion": "",
    "tokens_prompt": 76,
    "tokens_completion": 25,
    "duration_s": 3.883,
    "response_time_s": 3.883,
    "energy_wh_raw": 0.020569,
    "energy_wh_net": 0.020569,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q1",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A one\u2011word answer naming Japan\u2019s capital (Tokyo).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Very short prompt and answer provide a baseline for minimal energy consumption.",
    "tags": [
      "energy-baseline",
      "short-context",
      "factual"
    ],
    "wh_per_1k_tokens": 0.203653,
    "energy_kwh_per_token": 2.04e-07,
    "g_co2": 0.007199
  },
  {
    "prompt": "Calculate 7 + 5.",
    "completion": "",
    "tokens_prompt": 75,
    "tokens_completion": 35,
    "duration_s": 1.209,
    "response_time_s": 1.209,
    "energy_wh_raw": 0.015648,
    "energy_wh_net": 0.015648,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q2",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A single number representing the sum (12).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Simple arithmetic with minimal computation and output length.",
    "tags": [
      "numeric",
      "low-compute",
      "energy-baseline"
    ],
    "wh_per_1k_tokens": 0.142255,
    "energy_kwh_per_token": 1.42e-07,
    "g_co2": 0.005477
  },
  {
    "prompt": "Name the largest planet in our solar system.",
    "completion": "",
    "tokens_prompt": 77,
    "tokens_completion": 41,
    "duration_s": 1.364,
    "response_time_s": 1.364,
    "energy_wh_raw": 0.019064,
    "energy_wh_net": 0.019064,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q3",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The name of the largest planet (Jupiter).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short factual recall requiring little reasoning.",
    "tags": [
      "astronomy",
      "factual",
      "energy-baseline"
    ],
    "wh_per_1k_tokens": 0.161559,
    "energy_kwh_per_token": 1.62e-07,
    "g_co2": 0.006672
  },
  {
    "prompt": "What is the chemical symbol for water?",
    "completion": "",
    "tokens_prompt": 76,
    "tokens_completion": 112,
    "duration_s": 3.458,
    "response_time_s": 3.458,
    "energy_wh_raw": 0.050076,
    "energy_wh_net": 0.050076,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q4",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The two\u2011letter chemical formula (H2O).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short chemical knowledge question; minimal output.",
    "tags": [
      "chemistry",
      "short-output",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.266362,
    "energy_kwh_per_token": 2.66e-07,
    "g_co2": 0.017527
  },
  {
    "prompt": "Who wrote the play \u2018Romeo and Juliet\u2019?",
    "completion": "",
    "tokens_prompt": 78,
    "tokens_completion": 61,
    "duration_s": 2.004,
    "response_time_s": 2.004,
    "energy_wh_raw": 0.030511,
    "energy_wh_net": 0.030511,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q5",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The author\u2019s name (William Shakespeare).",
    "max_output_tokens_hint": 6,
    "energy_relevance": "Simple fact retrieval; low energy.",
    "tags": [
      "literature",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.219504,
    "energy_kwh_per_token": 2.2e-07,
    "g_co2": 0.010679
  },
  {
    "prompt": "In which year did humans first land on the Moon?",
    "completion": "",
    "tokens_prompt": 79,
    "tokens_completion": 42,
    "duration_s": 1.417,
    "response_time_s": 1.417,
    "energy_wh_raw": 0.020204,
    "energy_wh_net": 0.020204,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q6",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A four\u2011digit year (1969).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short question with numeric answer; minimal compute.",
    "tags": [
      "history",
      "numeric",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.166975,
    "energy_kwh_per_token": 1.67e-07,
    "g_co2": 0.007071
  },
  {
    "prompt": "Which element has the atomic number 6?",
    "completion": "",
    "tokens_prompt": 77,
    "tokens_completion": 27,
    "duration_s": 0.953,
    "response_time_s": 0.953,
    "energy_wh_raw": 0.011295,
    "energy_wh_net": 0.011295,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q7",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The element\u2019s name (Carbon).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Simple factual recall; low energy cost.",
    "tags": [
      "chemistry",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.108606,
    "energy_kwh_per_token": 1.09e-07,
    "g_co2": 0.003953
  },
  {
    "prompt": "What is the square root of 49?",
    "completion": "",
    "tokens_prompt": 77,
    "tokens_completion": 65,
    "duration_s": 2.098,
    "response_time_s": 2.098,
    "energy_wh_raw": 0.029069,
    "energy_wh_net": 0.029069,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q8",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A single integer (7).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Basic arithmetic with one\u2011word output.",
    "tags": [
      "math",
      "numeric",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.204711,
    "energy_kwh_per_token": 2.05e-07,
    "g_co2": 0.010174
  },
  {
    "prompt": "How many continents are there on Earth?",
    "completion": "",
    "tokens_prompt": 76,
    "tokens_completion": 53,
    "duration_s": 1.727,
    "response_time_s": 1.727,
    "energy_wh_raw": 0.022412,
    "energy_wh_net": 0.022412,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q9",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A small integer (7).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Short factual query; minimal compute and output.",
    "tags": [
      "geography",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.173736,
    "energy_kwh_per_token": 1.74e-07,
    "g_co2": 0.007844
  },
  {
    "prompt": "When you mix red and blue paint, what color do you get?",
    "completion": "",
    "tokens_prompt": 82,
    "tokens_completion": 103,
    "duration_s": 3.293,
    "response_time_s": 3.293,
    "energy_wh_raw": 0.044326,
    "energy_wh_net": 0.044326,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q10",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The resulting secondary color (purple or violet).",
    "max_output_tokens_hint": 6,
    "energy_relevance": "Simple fact with one\u2011word answer to establish baseline energy usage.",
    "tags": [
      "color-mixing",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.2396,
    "energy_kwh_per_token": 2.4e-07,
    "g_co2": 0.015514
  }
]