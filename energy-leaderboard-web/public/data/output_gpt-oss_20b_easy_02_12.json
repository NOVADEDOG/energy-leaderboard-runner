[
  {
    "prompt": "What is the capital city of Japan?",
    "completion": "The capital city of Japan is **Tokyo**.",
    "tokens_prompt": 75,
    "tokens_completion": 41,
    "duration_s": 20.252,
    "response_time_s": 20.252,
    "energy_wh_raw": 0.068099,
    "energy_wh_net": 0.068099,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q1",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A one\u2011word answer naming Japan\u2019s capital (Tokyo).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Very short prompt and answer provide a baseline for minimal energy consumption.",
    "tags": [
      "energy-baseline",
      "short-context",
      "factual"
    ],
    "wh_per_1k_tokens": 0.58706,
    "energy_kwh_per_token": 5.87e-07,
    "g_co2": 0.023835
  },
  {
    "prompt": "Calculate 7 + 5.",
    "completion": "7\u202f+\u202f5\u202f=\u202f12",
    "tokens_prompt": 74,
    "tokens_completion": 40,
    "duration_s": 6.832,
    "response_time_s": 6.832,
    "energy_wh_raw": 0.016775,
    "energy_wh_net": 0.016775,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q2",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A single number representing the sum (12).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Simple arithmetic with minimal computation and output length.",
    "tags": [
      "numeric",
      "low-compute",
      "energy-baseline"
    ],
    "wh_per_1k_tokens": 0.147149,
    "energy_kwh_per_token": 1.47e-07,
    "g_co2": 0.005871
  },
  {
    "prompt": "Name the largest planet in our solar system.",
    "completion": "The largest planet in our solar system is **Jupiter**.",
    "tokens_prompt": 76,
    "tokens_completion": 46,
    "duration_s": 7.636,
    "response_time_s": 7.636,
    "energy_wh_raw": 0.020018,
    "energy_wh_net": 0.020018,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q3",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The name of the largest planet (Jupiter).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short factual recall requiring little reasoning.",
    "tags": [
      "astronomy",
      "factual",
      "energy-baseline"
    ],
    "wh_per_1k_tokens": 0.164082,
    "energy_kwh_per_token": 1.64e-07,
    "g_co2": 0.007006
  },
  {
    "prompt": "What is the chemical symbol for water?",
    "completion": "The chemical formula (often called the \u201csymbol\u201d) for water is **H\u2082O** \u2013 two hydrogen atoms bonded to one oxygen atom.",
    "tokens_prompt": 75,
    "tokens_completion": 82,
    "duration_s": 14.334,
    "response_time_s": 14.334,
    "energy_wh_raw": 0.031421,
    "energy_wh_net": 0.031421,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q4",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The two\u2011letter chemical formula (H2O).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short chemical knowledge question; minimal output.",
    "tags": [
      "chemistry",
      "short-output",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.200134,
    "energy_kwh_per_token": 2e-07,
    "g_co2": 0.010997
  },
  {
    "prompt": "Who wrote the play \u2018Romeo and Juliet\u2019?",
    "completion": "\u201cRomeo and Juliet\u201d was written by **William Shakespeare**.",
    "tokens_prompt": 77,
    "tokens_completion": 51,
    "duration_s": 9.652,
    "response_time_s": 9.652,
    "energy_wh_raw": 0.026645,
    "energy_wh_net": 0.026645,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q5",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The author\u2019s name (William Shakespeare).",
    "max_output_tokens_hint": 6,
    "energy_relevance": "Simple fact retrieval; low energy.",
    "tags": [
      "literature",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.208164,
    "energy_kwh_per_token": 2.08e-07,
    "g_co2": 0.009326
  },
  {
    "prompt": "In which year did humans first land on the Moon?",
    "completion": "Humans first landed on the Moon in **1969**.",
    "tokens_prompt": 78,
    "tokens_completion": 51,
    "duration_s": 9.354,
    "response_time_s": 9.354,
    "energy_wh_raw": 0.022364,
    "energy_wh_net": 0.022364,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q6",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A four\u2011digit year (1969).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Short question with numeric answer; minimal compute.",
    "tags": [
      "history",
      "numeric",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.173364,
    "energy_kwh_per_token": 1.73e-07,
    "g_co2": 0.007827
  },
  {
    "prompt": "Which element has the atomic number 6?",
    "completion": "Element 6 is **carbon**.",
    "tokens_prompt": 76,
    "tokens_completion": 49,
    "duration_s": 9.196,
    "response_time_s": 9.196,
    "energy_wh_raw": 0.02069,
    "energy_wh_net": 0.02069,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q7",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The element\u2019s name (Carbon).",
    "max_output_tokens_hint": 5,
    "energy_relevance": "Simple factual recall; low energy cost.",
    "tags": [
      "chemistry",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.16552,
    "energy_kwh_per_token": 1.66e-07,
    "g_co2": 0.007241
  },
  {
    "prompt": "What is the square root of 49?",
    "completion": "The principal (positive) square root of\u202f49 is **7**. (Of course, the equation \\(x^2 = 49\\) has two solutions: \\(x = 7\\) and \\(x = -7\\).)",
    "tokens_prompt": 76,
    "tokens_completion": 105,
    "duration_s": 19.544,
    "response_time_s": 19.544,
    "energy_wh_raw": 0.04019,
    "energy_wh_net": 0.04019,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q8",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A single integer (7).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Basic arithmetic with one\u2011word output.",
    "tags": [
      "math",
      "numeric",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.222044,
    "energy_kwh_per_token": 2.22e-07,
    "g_co2": 0.014066
  },
  {
    "prompt": "How many continents are there on Earth?",
    "completion": "There are **seven continents** on Earth:\n\n1. Asia  \n2. Africa  \n3. North America  \n4. South America  \n5. Antarctica  \n6. Europe  \n7. Australia (sometimes called Oceania when including the Pacific islands)\n\nThese are the widely accepted continental divisions used in geography.",
    "tokens_prompt": 75,
    "tokens_completion": 129,
    "duration_s": 23.593,
    "response_time_s": 23.593,
    "energy_wh_raw": 0.046691,
    "energy_wh_net": 0.046691,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q9",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "A small integer (7).",
    "max_output_tokens_hint": 4,
    "energy_relevance": "Short factual query; minimal compute and output.",
    "tags": [
      "geography",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.228877,
    "energy_kwh_per_token": 2.29e-07,
    "g_co2": 0.016342
  },
  {
    "prompt": "When you mix red and blue paint, what color do you get?",
    "completion": "Mixing red and blue paint gives you a shade of **purple (or violet)**\u2014essentially a color that sits between the two in the spectrum. In practice, the exact hue can vary a bit depending on the particular paints (e.g., how much pigment each holds and whether the colors are warm or cool), but generally you end up with a purple tone.",
    "tokens_prompt": 81,
    "tokens_completion": 199,
    "duration_s": 35.674,
    "response_time_s": 35.674,
    "energy_wh_raw": 0.071203,
    "energy_wh_net": 0.071203,
    "provider": "ollama",
    "model": "gpt-oss:20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts1",
    "testset_name": "Short factual questions (low energy baseline)",
    "testset_goal": "Establish a low\u2011energy baseline by asking simple factual or arithmetic questions that require short, single\u2011sentence answers.",
    "testset_notes": "Use this set to measure the minimum energy cost of a local LLM under controlled conditions. Each prompt is concise, and the expected output is a short factual answer with minimal reasoning. Run multiple models on the same hardware and compare average energy per response.",
    "question_id": "ts1_q10",
    "question_difficulty": "easy",
    "question_task_type": "qa",
    "expected_answer_description": "The resulting secondary color (purple or violet).",
    "max_output_tokens_hint": 6,
    "energy_relevance": "Simple fact with one\u2011word answer to establish baseline energy usage.",
    "tags": [
      "color-mixing",
      "factual",
      "baseline"
    ],
    "wh_per_1k_tokens": 0.254296,
    "energy_kwh_per_token": 2.54e-07,
    "g_co2": 0.024921
  }
]