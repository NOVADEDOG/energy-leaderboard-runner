[
  {
    "prompt": "Summarize the following paragraph in two sentences: Artificial intelligence is a field that has seen rapid growth in the past decade. With the advent of deep learning, machines can now perform tasks such as image recognition, language translation, and even creative writing.",
    "completion": "Artificial intelligence has experienced rapid growth in the past decade, driven by advancements in deep learning. This has enabled machines to perform complex tasks such as image recognition, language translation, and creative writing.",
    "tokens_prompt": 60,
    "tokens_completion": 351,
    "duration_s": 19.564,
    "response_time_s": 19.563,
    "energy_wh_raw": 0.179631,
    "energy_wh_net": 0.179631,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q1",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Condenses the paragraph to two sentences mentioning AI\u2019s rapid growth and its applications like image recognition, translation and creative tasks.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Moderate summarization; tests energy usage for condensing information.",
    "tags": [
      "summarization",
      "mixed",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.437058,
    "energy_kwh_per_token": 4.37e-07,
    "g_co2": 0.062871
  },
  {
    "prompt": "Generate a short paragraph (50\u201370 words) describing a fictional planet with two suns.",
    "completion": "**Dyara**, a planet orbiting two suns\u2014**Solara** (amber) and **Virel** (violet)\u2014experiences perpetual twilight, with shifting skies painting the horizon in gradients of gold and indigo. Its twin suns create extreme temperature fluctuations, fostering biomes of crystalline forests and luminescent fungi. The inhabitants, the **Kaelari**, have evolved to harness the dual light for agriculture and navigation, their cities glowing with harvested solar energy. Dyara\u2019s unique celestial dance shapes its culture, science, and very essence. (70 words)",
    "tokens_prompt": 31,
    "tokens_completion": 301,
    "duration_s": 14.764,
    "response_time_s": 14.764,
    "energy_wh_raw": 0.142279,
    "energy_wh_net": 0.142279,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q2",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Creates a descriptive paragraph about a made\u2011up planet orbiting two stars, mentioning environmental features such as double shadows, long days or unique ecosystems.",
    "max_output_tokens_hint": 100,
    "energy_relevance": "Creative generation with word\u2011count constraint; longer output increases energy.",
    "tags": [
      "creative-writing",
      "description",
      "long-output"
    ],
    "wh_per_1k_tokens": 0.428551,
    "energy_kwh_per_token": 4.29e-07,
    "g_co2": 0.049798
  },
  {
    "prompt": "Write a JSON object with keys \u2018name\u2019, \u2018age\u2019 and \u2018favorite_color\u2019 representing a fictional character of your choice.",
    "completion": "{\n  \"name\": \"Elara\",\n  \"age\": 27,\n  \"favorite_color\": \"sapphire blue\"\n}",
    "tokens_prompt": 35,
    "tokens_completion": 376,
    "duration_s": 17.71,
    "response_time_s": 17.71,
    "energy_wh_raw": 0.168538,
    "energy_wh_net": 0.168538,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q3",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a valid JSON object with three key\u2013value pairs, e.g., {\"name\": \"Alex\", \"age\": 28, \"favorite_color\": \"green\"}.",
    "max_output_tokens_hint": 30,
    "energy_relevance": "Structured output generation; tests the model\u2019s ability to follow formatting instructions.",
    "tags": [
      "json",
      "structured-output",
      "short"
    ],
    "wh_per_1k_tokens": 0.410068,
    "energy_kwh_per_token": 4.1e-07,
    "g_co2": 0.058988
  },
  {
    "prompt": "Classify the following items as \u2018fruit\u2019 or \u2018vegetable\u2019: apple, carrot, banana, broccoli, tomato. Return your answer as a list of pairs [item, type].",
    "completion": "[[\"apple\", \"fruit\"], [\"carrot\", \"vegetable\"], [\"banana\", \"fruit\"], [\"broccoli\", \"vegetable\"], [\"tomato\", \"fruit\"]]",
    "tokens_prompt": 47,
    "tokens_completion": 922,
    "duration_s": 43.016,
    "response_time_s": 43.016,
    "energy_wh_raw": 0.420854,
    "energy_wh_net": 0.420854,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q4",
    "question_difficulty": "mixed",
    "question_task_type": "classification",
    "expected_answer_description": "Produces a list of pairs indicating fruit or vegetable classifications, e.g., [[\"apple\", \"fruit\"], \u2026].",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Requires producing a structured list and mapping categories; moderate reasoning and output length.",
    "tags": [
      "classification",
      "list",
      "structured-output"
    ],
    "wh_per_1k_tokens": 0.434318,
    "energy_kwh_per_token": 4.34e-07,
    "g_co2": 0.147299
  },
  {
    "prompt": "Translate this recipe step into Spanish: \u2018Chop the onions finely and saut\u00e9 them in olive oil until golden brown.\u2019",
    "completion": "Picar las cebollas finamente y sofre\u00edr las en aceite de oliva hasta que se doren.",
    "tokens_prompt": 35,
    "tokens_completion": 634,
    "duration_s": 29.609,
    "response_time_s": 29.609,
    "energy_wh_raw": 0.291194,
    "energy_wh_net": 0.291194,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q5",
    "question_difficulty": "mixed",
    "question_task_type": "translation",
    "expected_answer_description": "Provides a grammatically correct Spanish translation of the cooking instruction.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Short translation task; tests cross\u2011lingual capability with moderate compute.",
    "tags": [
      "translation",
      "cooking",
      "short"
    ],
    "wh_per_1k_tokens": 0.435268,
    "energy_kwh_per_token": 4.35e-07,
    "g_co2": 0.101918
  },
  {
    "prompt": "Given the numbers [4, 9, 16, 25], write a Python list comprehension to compute their square roots.",
    "completion": "To compute the square roots of the numbers `[4, 9, 16, 25]` using a Python list comprehension, we can utilize the exponentiation operator `**` with `0.5`. This is a concise and readable way to calculate square roots without the need for importing external modules like `math`.\n\nHere is the list comprehension:\n\n```python\n[x**0.5 for x in [4, 9, 16, 25]]\n```\n\n---\n\n### Explanation:\n\n- `x**0.5` computes the square root of each number `x` in the list.\n- The list comprehension iterates over each element in the original list `[4, 9, 16, 25]`.\n- The result will be a new list containing the square roots of the original numbers: `[2.0, 3.0, 4.0, 5.0]`.\n\n---\n\n### Alternative (Using `math.sqrt`):\n\nIf you prefer using the `math` module's `sqrt` function, you would need to import `math` first, and the list comprehension would look like this:\n\n```python\nimport math\n[math.sqrt(x) for x in [4, 9, 16, 25]]\n```\n\nHowever, since the question specifically asks for a list comprehension and not the full code, the first version using `x**0.5` is more direct and doesn't require any imports.\n\n---\n\n### Final Answer:\n\n```python\n[x**0.5 for x in [4, 9, 16, 25]]\n```",
    "tokens_prompt": 38,
    "tokens_completion": 1521,
    "duration_s": 70.671,
    "response_time_s": 70.671,
    "energy_wh_raw": 0.77197,
    "energy_wh_net": 0.77197,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q6",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a one\u2011line Python list comprehension that applies math.sqrt or exponent 0.5 to each number.",
    "max_output_tokens_hint": 50,
    "energy_relevance": "Generates code; tests ability to produce correct syntax and moderate output.",
    "tags": [
      "python",
      "list-comprehension",
      "code"
    ],
    "wh_per_1k_tokens": 0.49517,
    "energy_kwh_per_token": 4.95e-07,
    "g_co2": 0.27019
  },
  {
    "prompt": "Write a haiku (three lines with syllable pattern 5\u20137\u20135) about the changing seasons.",
    "completion": "Autumn leaves descend,  \nWind whispers through bare branches\u2014  \nSpring stirs in the soil.",
    "tokens_prompt": 33,
    "tokens_completion": 881,
    "duration_s": 40.878,
    "response_time_s": 40.878,
    "energy_wh_raw": 0.430552,
    "energy_wh_net": 0.430552,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q7",
    "question_difficulty": "mixed",
    "question_task_type": "other",
    "expected_answer_description": "Produces a three\u2011line haiku observing the 5\u20117\u20115 syllable structure and referencing seasonal change.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Creative poetry requires the model to track syllable counts; moderate compute despite short length.",
    "tags": [
      "poetry",
      "creative",
      "short"
    ],
    "wh_per_1k_tokens": 0.471063,
    "energy_kwh_per_token": 4.71e-07,
    "g_co2": 0.150693
  },
  {
    "prompt": "State the moral of Aesop\u2019s fable \u2018The Tortoise and the Hare\u2019 in one sentence.",
    "completion": "The moral of Aesop\u2019s fable *The Tortoise and the Hare* is that **slow and steady wins the race**, emphasizing the value of perseverance and humility over overconfidence and haste.",
    "tokens_prompt": 33,
    "tokens_completion": 305,
    "duration_s": 14.76,
    "response_time_s": 14.76,
    "energy_wh_raw": 0.156975,
    "energy_wh_net": 0.156975,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q8",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Summarizes the moral (steady effort and perseverance often outperform careless speed).",
    "max_output_tokens_hint": 25,
    "energy_relevance": "Short summarization; tests ability to capture key lesson succinctly.",
    "tags": [
      "fable",
      "moral",
      "short"
    ],
    "wh_per_1k_tokens": 0.464423,
    "energy_kwh_per_token": 4.64e-07,
    "g_co2": 0.054941
  },
  {
    "prompt": "Explain what a binary search algorithm does in two sentences.",
    "completion": "A binary search algorithm efficiently finds the position of a target value within a sorted array by repeatedly dividing the search interval in half. It compares the target with the middle element of the interval and narrows the search to the left or right half, achieving a time complexity of O(log n).",
    "tokens_prompt": 22,
    "tokens_completion": 256,
    "duration_s": 12.239,
    "response_time_s": 12.239,
    "energy_wh_raw": 0.123442,
    "energy_wh_net": 0.123442,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q9",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Describes that binary search repeatedly divides a sorted list to locate a target value by comparing the target to the middle element and narrowing the search interval.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Algorithm description requires concise reasoning; moderate output length.",
    "tags": [
      "computer-science",
      "algorithm",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.444036,
    "energy_kwh_per_token": 4.44e-07,
    "g_co2": 0.043205
  },
  {
    "prompt": "Given the string \u2018hello world\u2019, write pseudocode or simple code to reverse the string and briefly explain your approach.",
    "completion": "To reverse the string `'hello world'`, we can follow a simple and intuitive approach that involves iterating over the string from the last character to the first, appending each character to a new string. This method is both easy to understand and implement in most programming languages.\n\n---\n\n### \u2705 **Pseudocode**\n\n```plaintext\nInput: string = 'hello world'\nOutput: reversedString\n\nInitialize reversedString as an empty string\nFor i from length of string - 1 down to 0:\n    reversedString = reversedString + string[i]\nReturn reversedString\n```\n\n---\n\n### \ud83e\udde0 **Explanation**\n\n1. **Initialization**: Start with an empty string (`reversedString`) to store the result.\n2. **Loop**: Traverse the original string from the last index (i.e., `length - 1`) to the first index (i.e., `0`), using a step of `-1`.\n3. **Concatenation**: In each iteration, take the character at the current index and append it to the `reversedString`.\n4. **Result**: After the loop completes, the `reversedString` will contain the reversed version of the input string.\n\n---\n\n### \ud83e\uddea **Example Execution**\n\nFor the input `'hello world'`:\n- The loop starts at index `10` (character `'d'`) and moves to index `0` (character `'h'`).\n- The characters are appended in reverse order: `'d'`, `'l'`, `'r'`, `'o'`, `'w'`, `' '`, `'o'`, `'l'`, `'l'`, `'e'`, `'h'`.\n- The final reversed string is `'dlrow olleh'`.\n\n---\n\n### \ud83e\uddfe **Code Example (Python)**\n\n```python\ns = 'hello world'\nreversed_s = ''\nfor i in range(len(s) - 1, -1, -1):\n    reversed_s += s[i]\nprint(reversed_s)\n```\n\n**Output:**\n```\ndlrow olleh\n```\n\n---\n\n### \ud83d\udccc **Alternative (Using Built-in Functions)**\n\nIn Python, you can also reverse the string more concisely using built-in functions:\n\n```python\ns = 'hello world'\nreversed_s = ''.join(reversed(s))\nprint(reversed_s)\n```\n\n**Output:**\n```\ndlrow olleh\n```\n\n---\n\n### \u2705 **Conclusion**\n\nThe approach is efficient and clear, making it ideal for beginners. It leverages basic string indexing and concatenation to build the reversed string step by step, ensuring correctness and simplicity.",
    "tokens_prompt": 33,
    "tokens_completion": 1612,
    "duration_s": 76.607,
    "response_time_s": 76.607,
    "energy_wh_raw": 0.825084,
    "energy_wh_net": 0.825084,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q10",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Provides pseudocode or a short function that iterates over the characters or uses slicing to reverse the string and explains the method.",
    "max_output_tokens_hint": 80,
    "energy_relevance": "Combines code and explanation; increases output length and tests multi\u2011modal reasoning.",
    "tags": [
      "coding",
      "string-manipulation",
      "explanation"
    ],
    "wh_per_1k_tokens": 0.501571,
    "energy_kwh_per_token": 5.02e-07,
    "g_co2": 0.288779
  }
]
