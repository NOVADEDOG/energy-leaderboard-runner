[
  {
    "prompt": "Summarize the following paragraph in two sentences: Artificial intelligence is a field that has seen rapid growth in the past decade. With the advent of deep learning, machines can now perform tasks such as image recognition, language translation, and even creative writing.",
    "completion": "Artificial intelligence has experienced rapid growth in the past decade, driven by advancements in deep learning. This has enabled machines to perform complex tasks such as image recognition, language translation, and creative writing.",
    "tokens_prompt": 60,
    "tokens_completion": 261,
    "duration_s": 31.281,
    "response_time_s": 31.281,
    "energy_wh_raw": 0.146895,
    "energy_wh_net": 0.146895,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q1",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Condenses the paragraph to two sentences mentioning AI\u2019s rapid growth and its applications like image recognition, translation and creative tasks.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Moderate summarization; tests energy usage for condensing information.",
    "tags": [
      "summarization",
      "mixed",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.457617,
    "energy_kwh_per_token": 4.58e-07,
    "g_co2": 0.051413
  },
  {
    "prompt": "Generate a short paragraph (50\u201370 words) describing a fictional planet with two suns.",
    "completion": "Nestled in a binary star system, Dyversa orbits two luminous suns, casting shifting shadows and painting skies in hues of amber and violet. Its twin stars create perpetual twilight, fostering a temperate climate where bioluminescent flora thrive. Rivers of liquid silver flow through crystalline valleys, while twin suns sculpt dramatic day-night cycles. Creatures with adaptive camouflage navigate the ever-changing light, making Dyversa a realm of perpetual wonder. (70 words)",
    "tokens_prompt": 31,
    "tokens_completion": 332,
    "duration_s": 39.671,
    "response_time_s": 39.671,
    "energy_wh_raw": 0.183057,
    "energy_wh_net": 0.183057,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q2",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Creates a descriptive paragraph about a made\u2011up planet orbiting two stars, mentioning environmental features such as double shadows, long days or unique ecosystems.",
    "max_output_tokens_hint": 100,
    "energy_relevance": "Creative generation with word\u2011count constraint; longer output increases energy.",
    "tags": [
      "creative-writing",
      "description",
      "long-output"
    ],
    "wh_per_1k_tokens": 0.504289,
    "energy_kwh_per_token": 5.04e-07,
    "g_co2": 0.06407
  },
  {
    "prompt": "Write a JSON object with keys \u2018name\u2019, \u2018age\u2019 and \u2018favorite_color\u2019 representing a fictional character of your choice.",
    "completion": "{\n  \"name\": \"Elara\",\n  \"age\": 27,\n  \"favorite_color\": \"indigo\"\n}",
    "tokens_prompt": 35,
    "tokens_completion": 640,
    "duration_s": 76.938,
    "response_time_s": 76.938,
    "energy_wh_raw": 0.353373,
    "energy_wh_net": 0.353373,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q3",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a valid JSON object with three key\u2013value pairs, e.g., {\"name\": \"Alex\", \"age\": 28, \"favorite_color\": \"green\"}.",
    "max_output_tokens_hint": 30,
    "energy_relevance": "Structured output generation; tests the model\u2019s ability to follow formatting instructions.",
    "tags": [
      "json",
      "structured-output",
      "short"
    ],
    "wh_per_1k_tokens": 0.523516,
    "energy_kwh_per_token": 5.24e-07,
    "g_co2": 0.123681
  },
  {
    "prompt": "Classify the following items as \u2018fruit\u2019 or \u2018vegetable\u2019: apple, carrot, banana, broccoli, tomato. Return your answer as a list of pairs [item, type].",
    "completion": "[apple, fruit], [carrot, vegetable], [banana, fruit], [broccoli, vegetable], [tomato, fruit]",
    "tokens_prompt": 47,
    "tokens_completion": 691,
    "duration_s": 82.702,
    "response_time_s": 82.701,
    "energy_wh_raw": 0.380485,
    "energy_wh_net": 0.380485,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q4",
    "question_difficulty": "mixed",
    "question_task_type": "classification",
    "expected_answer_description": "Produces a list of pairs indicating fruit or vegetable classifications, e.g., [[\"apple\", \"fruit\"], \u2026].",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Requires producing a structured list and mapping categories; moderate reasoning and output length.",
    "tags": [
      "classification",
      "list",
      "structured-output"
    ],
    "wh_per_1k_tokens": 0.515562,
    "energy_kwh_per_token": 5.16e-07,
    "g_co2": 0.13317
  },
  {
    "prompt": "Translate this recipe step into Spanish: \u2018Chop the onions finely and saut\u00e9 them in olive oil until golden brown.\u2019",
    "completion": "Picar las cebollas finamente y sofre\u00edrlas en aceite de oliva hasta que est\u00e9n doradas.",
    "tokens_prompt": 35,
    "tokens_completion": 450,
    "duration_s": 53.343,
    "response_time_s": 53.343,
    "energy_wh_raw": 0.246735,
    "energy_wh_net": 0.246735,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q5",
    "question_difficulty": "mixed",
    "question_task_type": "translation",
    "expected_answer_description": "Provides a grammatically correct Spanish translation of the cooking instruction.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Short translation task; tests cross\u2011lingual capability with moderate compute.",
    "tags": [
      "translation",
      "cooking",
      "short"
    ],
    "wh_per_1k_tokens": 0.508732,
    "energy_kwh_per_token": 5.09e-07,
    "g_co2": 0.086357
  },
  {
    "prompt": "Given the numbers [4, 9, 16, 25], write a Python list comprehension to compute their square roots.",
    "completion": "To compute the square roots of the numbers `[4, 9, 16, 25]` using a Python list comprehension, you can utilize the `math.sqrt()` function from the `math` module. This method is both clear and idiomatic for performing square root operations in Python.\n\nHere is the list comprehension that accomplishes this:\n\n```python\n[math.sqrt(num) for num in [4, 9, 16, 25]]\n```\n\n---\n\n### Explanation:\n\n- **`math.sqrt(num)`**: This is the function used to compute the square root of each number in the list. The `math` module must be imported for this to work.\n- **`for num in [4, 9, 16, 25]`**: This is the iteration part of the list comprehension, which loops through each number in the provided list.\n- **Result**: The list comprehension evaluates each number and returns a new list containing the square roots of the original numbers.\n\n---\n\n### Final Answer:\n\n```python\n[math.sqrt(num) for num in [4, 9, 16, 25]]\n```\n\nThis expression will produce the output: `[2.0, 3.0, 4.0, 5.0]`.\n\n---\n\n### Note:\n\nWhile you could also use `num ** 0.5` as an alternative, `math.sqrt()` is more readable and semantically clearer for square root operations. If you prefer to avoid importing the `math` module, the exponent approach is also valid. However, the `math.sqrt()` method is generally preferred in Python for its clarity and performance.",
    "tokens_prompt": 38,
    "tokens_completion": 2035,
    "duration_s": 261.137,
    "response_time_s": 261.137,
    "energy_wh_raw": 1.172949,
    "energy_wh_net": 1.172949,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q6",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a one\u2011line Python list comprehension that applies math.sqrt or exponent 0.5 to each number.",
    "max_output_tokens_hint": 50,
    "energy_relevance": "Generates code; tests ability to produce correct syntax and moderate output.",
    "tags": [
      "python",
      "list-comprehension",
      "code"
    ],
    "wh_per_1k_tokens": 0.565822,
    "energy_kwh_per_token": 5.66e-07,
    "g_co2": 0.410532
  },
  {
    "prompt": "Write a haiku (three lines with syllable pattern 5\u20137\u20135) about the changing seasons.",
    "completion": "Crimson leaves descend,  \nwind whispers winter's breath through trees\u2014  \nearth sleeps beneath frost.",
    "tokens_prompt": 33,
    "tokens_completion": 723,
    "duration_s": 89.834,
    "response_time_s": 89.834,
    "energy_wh_raw": 0.408078,
    "energy_wh_net": 0.408078,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q7",
    "question_difficulty": "mixed",
    "question_task_type": "other",
    "expected_answer_description": "Produces a three\u2011line haiku observing the 5\u20117\u20115 syllable structure and referencing seasonal change.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Creative poetry requires the model to track syllable counts; moderate compute despite short length.",
    "tags": [
      "poetry",
      "creative",
      "short"
    ],
    "wh_per_1k_tokens": 0.539786,
    "energy_kwh_per_token": 5.4e-07,
    "g_co2": 0.142827
  },
  {
    "prompt": "State the moral of Aesop\u2019s fable \u2018The Tortoise and the Hare\u2019 in one sentence.",
    "completion": "The moral of Aesop\u2019s fable *The Tortoise and the Hare* is that perseverance and steady effort will ultimately triumph over arrogance and overconfidence.",
    "tokens_prompt": 33,
    "tokens_completion": 209,
    "duration_s": 25.607,
    "response_time_s": 25.607,
    "energy_wh_raw": 0.118611,
    "energy_wh_net": 0.118611,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q8",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Summarizes the moral (steady effort and perseverance often outperform careless speed).",
    "max_output_tokens_hint": 25,
    "energy_relevance": "Short summarization; tests ability to capture key lesson succinctly.",
    "tags": [
      "fable",
      "moral",
      "short"
    ],
    "wh_per_1k_tokens": 0.490128,
    "energy_kwh_per_token": 4.9e-07,
    "g_co2": 0.041514
  },
  {
    "prompt": "Explain what a binary search algorithm does in two sentences.",
    "completion": "Binary search is an efficient algorithm that finds an element in a sorted array by repeatedly dividing the search interval in half. It compares the target value to the middle element and eliminates half of the remaining elements with each step, achieving a time complexity of O(log n).",
    "tokens_prompt": 22,
    "tokens_completion": 309,
    "duration_s": 36.732,
    "response_time_s": 36.732,
    "energy_wh_raw": 0.169953,
    "energy_wh_net": 0.169953,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q9",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Describes that binary search repeatedly divides a sorted list to locate a target value by comparing the target to the middle element and narrowing the search interval.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Algorithm description requires concise reasoning; moderate output length.",
    "tags": [
      "computer-science",
      "algorithm",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.513453,
    "energy_kwh_per_token": 5.13e-07,
    "g_co2": 0.059484
  },
  {
    "prompt": "Given the string \u2018hello world\u2019, write pseudocode or simple code to reverse the string and briefly explain your approach.",
    "completion": "To reverse the string `'hello world'`, we can follow a simple approach that involves iterating through the string from the last character to the first and building a new string. This method works in most programming languages and is straightforward to implement.\n\n---\n\n### \u2705 **Pseudocode:**\n\n```plaintext\nFUNCTION reverseString(s):\n    reversedStr = \"\"\n    FOR i FROM length(s) - 1 DOWN TO 0:\n        reversedStr = reversedStr + s[i]\n    RETURN reversedStr\n```\n\n---\n\n### \ud83e\udde0 **Explanation:**\n\n1. **Initialize an empty string** `reversedStr` to store the result.\n2. **Iterate from the last index to the first** of the input string `s`.\n3. **Append each character** to `reversedStr` during the iteration.\n4. **Return the final reversed string** after the loop completes.\n\n---\n\n### \ud83e\uddea **Example (Python Code):**\n\n```python\ns = 'hello world'\nreversed_s = ''\nfor i in range(len(s) - 1, -1, -1):\n    reversed_s += s[i]\nprint(reversed_s)  # Output: 'dlrow olleh'\n```\n\n---\n\n### \ud83d\udccc **Alternative (Python-Specific):**\n\nIf you're using Python, you can achieve this more concisely with slicing:\n\n```python\ns = 'hello world'\nreversed_s = s[::-1]\nprint(reversed_s)  # Output: 'dlrow olleh'\n```\n\n---\n\n### \ud83d\udccc **Key Points:**\n\n- This approach is **O(n)** in time complexity, where `n` is the length of the string.\n- It uses **O(n)** space to store the reversed string.\n- The method works for any string, including empty strings or strings with special characters.\n\n---\n\n### \u2705 **Summary:**\n\nThe approach iterates through the string in reverse order, appending each character to a new string, which results in the original string being reversed. This is both simple and efficient for most use cases.",
    "tokens_prompt": 33,
    "tokens_completion": 1443,
    "duration_s": 177.34,
    "response_time_s": 177.34,
    "energy_wh_raw": 0.803203,
    "energy_wh_net": 0.803203,
    "provider": "ollama",
    "model": "qwen3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with Quadro T2000 with Max-Q Design",
    "device_type": "nvidia",
    "os_name": "Linux",
    "os_version": "5.15.167.4-microsoft-standard-WSL2",
    "cpu_model": "Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz",
    "gpu_model": "Quadro T2000 with Max-Q Design",
    "ram_gb": 31.2,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q10",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Provides pseudocode or a short function that iterates over the characters or uses slicing to reverse the string and explains the method.",
    "max_output_tokens_hint": 80,
    "energy_relevance": "Combines code and explanation; increases output length and tests multi\u2011modal reasoning.",
    "tags": [
      "coding",
      "string-manipulation",
      "explanation"
    ],
    "wh_per_1k_tokens": 0.544175,
    "energy_kwh_per_token": 5.44e-07,
    "g_co2": 0.281121
  }
]