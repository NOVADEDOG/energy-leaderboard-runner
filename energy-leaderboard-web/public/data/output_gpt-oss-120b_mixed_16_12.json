[
  {
    "prompt": "Summarize the following paragraph in two sentences: Artificial intelligence is a field that has seen rapid growth in the past decade. With the advent of deep learning, machines can now perform tasks such as image recognition, language translation, and even creative writing.",
    "completion": "Artificial intelligence has expanded dramatically over the last ten years, driven largely by advances in deep learning. This progress now enables machines to handle complex tasks such as image recognition, language translation, and even creative writing.",
    "tokens_prompt": 117,
    "tokens_completion": 67,
    "duration_s": 1.781,
    "response_time_s": 1.781,
    "energy_wh_raw": 0.022764,
    "energy_wh_net": 0.022764,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q1",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Condenses the paragraph to two sentences mentioning AI\u2019s rapid growth and its applications like image recognition, translation and creative tasks.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Moderate summarization; tests energy usage for condensing information.",
    "tags": [
      "summarization",
      "mixed",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.123717,
    "energy_kwh_per_token": 1.24e-07,
    "g_co2": 0.007967
  },
  {
    "prompt": "Generate a short paragraph (50\u201370 words) describing a fictional planet with two suns.",
    "completion": "Orbiting twin suns, the planet of Virelia basks in perpetual twilight, where amber and violet hues dance across endless dunes of glassy quartz. Twin shadows stretch across molten rivers, and bioluminescent flora flicker like distant lanterns. The sky shimmers with double dawns, casting a warm, golden glow that nurtures a resilient, ever\u2011watchful civilization. Their songs echo across the violet horizons, binding generations together.",
    "tokens_prompt": 85,
    "tokens_completion": 486,
    "duration_s": 9.567,
    "response_time_s": 9.567,
    "energy_wh_raw": 0.142553,
    "energy_wh_net": 0.142553,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q2",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Creates a descriptive paragraph about a made\u2011up planet orbiting two stars, mentioning environmental features such as double shadows, long days or unique ecosystems.",
    "max_output_tokens_hint": 100,
    "energy_relevance": "Creative generation with word\u2011count constraint; longer output increases energy.",
    "tags": [
      "creative-writing",
      "description",
      "long-output"
    ],
    "wh_per_1k_tokens": 0.249655,
    "energy_kwh_per_token": 2.5e-07,
    "g_co2": 0.049894
  },
  {
    "prompt": "Write a JSON object with keys \u2018name\u2019, \u2018age\u2019 and \u2018favorite_color\u2019 representing a fictional character of your choice.",
    "completion": "```json\n{\n  \"name\": \"Sherlock Holmes\",\n  \"age\": 40,\n  \"favorite_color\": \"deep blue\"\n}\n```",
    "tokens_prompt": 92,
    "tokens_completion": 105,
    "duration_s": 2.304,
    "response_time_s": 2.304,
    "energy_wh_raw": 0.035223,
    "energy_wh_net": 0.035223,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q3",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a valid JSON object with three key\u2013value pairs, e.g., {\"name\": \"Alex\", \"age\": 28, \"favorite_color\": \"green\"}.",
    "max_output_tokens_hint": 30,
    "energy_relevance": "Structured output generation; tests the model\u2019s ability to follow formatting instructions.",
    "tags": [
      "json",
      "structured-output",
      "short"
    ],
    "wh_per_1k_tokens": 0.178797,
    "energy_kwh_per_token": 1.79e-07,
    "g_co2": 0.012328
  },
  {
    "prompt": "Classify the following items as \u2018fruit\u2019 or \u2018vegetable\u2019: apple, carrot, banana, broccoli, tomato. Return your answer as a list of pairs [item, type].",
    "completion": "[\n  [\"apple\", \"fruit\"],\n  [\"carrot\", \"vegetable\"],\n  [\"banana\", \"fruit\"],\n  [\"broccoli\", \"vegetable\"],\n  [\"tomato\", \"fruit\"]\n]",
    "tokens_prompt": 104,
    "tokens_completion": 205,
    "duration_s": 4.415,
    "response_time_s": 4.415,
    "energy_wh_raw": 0.061028,
    "energy_wh_net": 0.061028,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q4",
    "question_difficulty": "mixed",
    "question_task_type": "classification",
    "expected_answer_description": "Produces a list of pairs indicating fruit or vegetable classifications, e.g., [[\"apple\", \"fruit\"], \u2026].",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Requires producing a structured list and mapping categories; moderate reasoning and output length.",
    "tags": [
      "classification",
      "list",
      "structured-output"
    ],
    "wh_per_1k_tokens": 0.197502,
    "energy_kwh_per_token": 1.98e-07,
    "g_co2": 0.02136
  },
  {
    "prompt": "Translate this recipe step into Spanish: \u2018Chop the onions finely and saut\u00e9 them in olive oil until golden brown.\u2019",
    "completion": "Pica finamente las cebollas y salt\u00e9alas en aceite de oliva hasta que est\u00e9n doradas.",
    "tokens_prompt": 90,
    "tokens_completion": 112,
    "duration_s": 2.39,
    "response_time_s": 2.39,
    "energy_wh_raw": 0.035305,
    "energy_wh_net": 0.035305,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q5",
    "question_difficulty": "mixed",
    "question_task_type": "translation",
    "expected_answer_description": "Provides a grammatically correct Spanish translation of the cooking instruction.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Short translation task; tests cross\u2011lingual capability with moderate compute.",
    "tags": [
      "translation",
      "cooking",
      "short"
    ],
    "wh_per_1k_tokens": 0.174777,
    "energy_kwh_per_token": 1.75e-07,
    "g_co2": 0.012357
  },
  {
    "prompt": "Given the numbers [4, 9, 16, 25], write a Python list comprehension to compute their square roots.",
    "completion": "You can use a list comprehension together with `math.sqrt` (or the exponent `**0.5`) to get the square roots:\n\n```python\nimport math\n\nnumbers = [4, 9, 16, 25]\n\n# Using math.sqrt\nroots = [math.sqrt(n) for n in numbers]\nprint(roots)          # [2.0, 3.0, 4.0, 5.0]\n\n# ---- or ----\n# Using the exponent operator\nroots = [n**0.5 for n in numbers]\nprint(roots)          # [2.0, 3.0, 4.0, 5.0]\n```\n\nBoth versions produce the list of square roots: `[2.0, 3.0, 4.0, 5.0]`.",
    "tokens_prompt": 93,
    "tokens_completion": 223,
    "duration_s": 4.622,
    "response_time_s": 4.622,
    "energy_wh_raw": 0.052797,
    "energy_wh_net": 0.052797,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q6",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a one\u2011line Python list comprehension that applies math.sqrt or exponent 0.5 to each number.",
    "max_output_tokens_hint": 50,
    "energy_relevance": "Generates code; tests ability to produce correct syntax and moderate output.",
    "tags": [
      "python",
      "list-comprehension",
      "code"
    ],
    "wh_per_1k_tokens": 0.167079,
    "energy_kwh_per_token": 1.67e-07,
    "g_co2": 0.018479
  },
  {
    "prompt": "Write a haiku (three lines with syllable pattern 5\u20137\u20135) about the changing seasons.",
    "completion": "Leaves whisper in gold  \nWinter\u2019s breath thaws into bloom  \nSun sighs, rain returns",
    "tokens_prompt": 90,
    "tokens_completion": 260,
    "duration_s": 5.331,
    "response_time_s": 5.331,
    "energy_wh_raw": 0.06079,
    "energy_wh_net": 0.06079,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q7",
    "question_difficulty": "mixed",
    "question_task_type": "other",
    "expected_answer_description": "Produces a three\u2011line haiku observing the 5\u20117\u20115 syllable structure and referencing seasonal change.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Creative poetry requires the model to track syllable counts; moderate compute despite short length.",
    "tags": [
      "poetry",
      "creative",
      "short"
    ],
    "wh_per_1k_tokens": 0.173686,
    "energy_kwh_per_token": 1.74e-07,
    "g_co2": 0.021277
  },
  {
    "prompt": "State the moral of Aesop\u2019s fable \u2018The Tortoise and the Hare\u2019 in one sentence.",
    "completion": "Steady, persistent effort wins the race, while overconfidence and carelessness lead to failure.",
    "tokens_prompt": 90,
    "tokens_completion": 44,
    "duration_s": 1.108,
    "response_time_s": 1.108,
    "energy_wh_raw": 0.016076,
    "energy_wh_net": 0.016076,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q8",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Summarizes the moral (steady effort and perseverance often outperform careless speed).",
    "max_output_tokens_hint": 25,
    "energy_relevance": "Short summarization; tests ability to capture key lesson succinctly.",
    "tags": [
      "fable",
      "moral",
      "short"
    ],
    "wh_per_1k_tokens": 0.11997,
    "energy_kwh_per_token": 1.2e-07,
    "g_co2": 0.005627
  },
  {
    "prompt": "Explain what a binary search algorithm does in two sentences.",
    "completion": "A binary search algorithm efficiently finds a target value within a **sorted** list by repeatedly dividing the search interval in half: it compares the target to the middle element, discarding the half that cannot contain the target, and then continues the process on the remaining half. This halving continues until the target is found or the interval becomes empty, yielding a worst\u2011case time complexity of\u202fO(log\u202fn).",
    "tokens_prompt": 78,
    "tokens_completion": 108,
    "duration_s": 2.266,
    "response_time_s": 2.266,
    "energy_wh_raw": 0.032754,
    "energy_wh_net": 0.032754,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q9",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Describes that binary search repeatedly divides a sorted list to locate a target value by comparing the target to the middle element and narrowing the search interval.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Algorithm description requires concise reasoning; moderate output length.",
    "tags": [
      "computer-science",
      "algorithm",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.176097,
    "energy_kwh_per_token": 1.76e-07,
    "g_co2": 0.011464
  },
  {
    "prompt": "Given the string \u2018hello world\u2019, write pseudocode or simple code to reverse the string and briefly explain your approach.",
    "completion": "**Solution (Python\u2011style code)**  \n\n```python\ns = \"hello world\"          # original string\nrev = \"\"                    # will hold the reversed string\n\n# walk through the original string from the last character to the first\nfor i in range(len(s) - 1, -1, -1):\n    rev += s[i]             # append each character to the result\n\nprint(rev)                  # \u2192 \"dlrow olleh\"\n```\n\n**Explanation of the approach**\n\n1. **Identify the input** \u2013 `s` holds the text we want to reverse.  \n2. **Create an empty accumulator** \u2013 `rev` will be built character\u2011by\u2011character.  \n3. **Iterate backwards** \u2013 `range(len(s)-1, -1, -1)` produces the indices of `s` in reverse order (last index \u2192 0).  \n4. **Append each character** \u2013 For each index `i`, we take `s[i]` (the character at that position) and concatenate it to `rev`.  \n5. **Result** \u2013 After the loop finishes, `rev` contains the original string in reverse order, which we print.\n\nThe core idea is simple: walk through the string from the end to the beginning and collect the characters in that order. In many languages you could also use a built\u2011in reverse operation (e.g., `s[::-1]` in Python, `reverse()` on a character array in Java, etc.), but the loop shown works everywhere and makes the reversal logic explicit.",
    "tokens_prompt": 90,
    "tokens_completion": 412,
    "duration_s": 8.281,
    "response_time_s": 8.281,
    "energy_wh_raw": 0.097045,
    "energy_wh_net": 0.097045,
    "provider": "openai",
    "model": "gpt-oss-120b-MXFP4-00001-of-00002.gguf",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Linux with GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "GPU[0]\t\t: Card Series: \t\tAMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q10",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Provides pseudocode or a short function that iterates over the characters or uses slicing to reverse the string and explains the method.",
    "max_output_tokens_hint": 80,
    "energy_relevance": "Combines code and explanation; increases output length and tests multi\u2011modal reasoning.",
    "tags": [
      "coding",
      "string-manipulation",
      "explanation"
    ],
    "wh_per_1k_tokens": 0.193317,
    "energy_kwh_per_token": 1.93e-07,
    "g_co2": 0.033966
  }
]