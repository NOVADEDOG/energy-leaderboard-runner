[
  {
    "prompt": "Summarize the following paragraph in two sentences: Artificial intelligence is a field that has seen rapid growth in the past decade. With the advent of deep learning, machines can now perform tasks such as image recognition, language translation, and even creative writing.",
    "completion": "Here\u2019s a two-sentence summary of the paragraph:\n\nArtificial intelligence has experienced significant growth, largely driven by advancements in deep learning. This technology allows machines to accomplish increasingly complex tasks, including image recognition and creative writing.",
    "tokens_prompt": 58,
    "tokens_completion": 46,
    "duration_s": 3.426,
    "response_time_s": 3.426,
    "energy_wh_raw": 0.016088,
    "energy_wh_net": 0.016088,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q1",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Condenses the paragraph to two sentences mentioning AI\u2019s rapid growth and its applications like image recognition, translation and creative tasks.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Moderate summarization; tests energy usage for condensing information.",
    "tags": [
      "summarization",
      "mixed",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.154692,
    "energy_kwh_per_token": 1.55e-07,
    "g_co2": 0.005631
  },
  {
    "prompt": "Generate a short paragraph (50\u201370 words) describing a fictional planet with two suns.",
    "completion": "Xylos orbits a binary star system, perpetually bathed in the warm orange glow of Solara and the cooler, violet light of Umbra. Days are long and dramatic, shifting from a fiery, almost blinding brightness to a softer, ethereal twilight. The dual suns cast elongated shadows across the crimson deserts and jagged, obsidian mountains, creating a landscape of constant, mesmerizing contrast and unpredictable light patterns. Life here has adapted to this extreme environment, exhibiting bioluminescence and a unique circadian rhythm.",
    "tokens_prompt": 30,
    "tokens_completion": 99,
    "duration_s": 3.031,
    "response_time_s": 3.031,
    "energy_wh_raw": 0.024513,
    "energy_wh_net": 0.024513,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q2",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Creates a descriptive paragraph about a made\u2011up planet orbiting two stars, mentioning environmental features such as double shadows, long days or unique ecosystems.",
    "max_output_tokens_hint": 100,
    "energy_relevance": "Creative generation with word\u2011count constraint; longer output increases energy.",
    "tags": [
      "creative-writing",
      "description",
      "long-output"
    ],
    "wh_per_1k_tokens": 0.190023,
    "energy_kwh_per_token": 1.9e-07,
    "g_co2": 0.00858
  },
  {
    "prompt": "Write a JSON object with keys \u2018name\u2019, \u2018age\u2019 and \u2018favorite_color\u2019 representing a fictional character of your choice.",
    "completion": "```json\n{\n  \"name\": \"Elara Meadowlight\",\n  \"age\": 27,\n  \"favorite_color\": \"Forest Green\"\n}\n```\n",
    "tokens_prompt": 35,
    "tokens_completion": 41,
    "duration_s": 1.38,
    "response_time_s": 1.38,
    "energy_wh_raw": 0.009074,
    "energy_wh_net": 0.009074,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q3",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a valid JSON object with three key\u2013value pairs, e.g., {\"name\": \"Alex\", \"age\": 28, \"favorite_color\": \"green\"}.",
    "max_output_tokens_hint": 30,
    "energy_relevance": "Structured output generation; tests the model\u2019s ability to follow formatting instructions.",
    "tags": [
      "json",
      "structured-output",
      "short"
    ],
    "wh_per_1k_tokens": 0.119395,
    "energy_kwh_per_token": 1.19e-07,
    "g_co2": 0.003176
  },
  {
    "prompt": "Classify the following items as \u2018fruit\u2019 or \u2018vegetable\u2019: apple, carrot, banana, broccoli, tomato. Return your answer as a list of pairs [item, type].",
    "completion": "Here's the classification of the items as a list of pairs:\n\n[('apple', 'fruit'), ('carrot', 'vegetable'), ('banana', 'fruit'), ('broccoli', 'vegetable'), ('tomato', 'fruit')]",
    "tokens_prompt": 46,
    "tokens_completion": 49,
    "duration_s": 1.653,
    "response_time_s": 1.653,
    "energy_wh_raw": 0.011635,
    "energy_wh_net": 0.011635,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q4",
    "question_difficulty": "mixed",
    "question_task_type": "classification",
    "expected_answer_description": "Produces a list of pairs indicating fruit or vegetable classifications, e.g., [[\"apple\", \"fruit\"], \u2026].",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Requires producing a structured list and mapping categories; moderate reasoning and output length.",
    "tags": [
      "classification",
      "list",
      "structured-output"
    ],
    "wh_per_1k_tokens": 0.122474,
    "energy_kwh_per_token": 1.22e-07,
    "g_co2": 0.004072
  },
  {
    "prompt": "Translate this recipe step into Spanish: \u2018Chop the onions finely and saut\u00e9 them in olive oil until golden brown.\u2019",
    "completion": "Here are a few options for translating that recipe step into Spanish, with slightly different nuances:\n\n**Option 1 (Most Common & Natural):**\n\n\"Picar las cebollas finamente y sofre\u00edrlas en aceite de oliva hasta que est\u00e9n doradas.\"\n\n*   **Picar:** To chop\n*   **las cebollas:** the onions\n*   **finamente:** finely\n*   **sofre\u00edrlas:** to saut\u00e9 them (using the reflexive form because it's affecting the onions)\n*   **en aceite de oliva:** in olive oil\n*   **hasta que est\u00e9n doradas:** until they are golden brown.\n\n**Option 2 (Slightly more formal):**\n\n\"Cortar las cebollas finamente y sofre\u00edrlas en aceite de oliva hasta que queden doradas.\"\n\n*   **Cortar:** To cut (alternative to \"picar\")\n*   **en aceite de oliva:** in olive oil\n*   **hasta que est\u00e9n doradas:** until they are golden brown.\n\n**Option 3 (More descriptive):**\n\n\"Rallar las cebollas finamente y saltearlas en aceite de oliva hasta que adquieran un color dorado.\"\n\n*   **Rallar:** To shred (This is a valid option if you are shredding the onions)\n*   **saltearlas:** To saut\u00e9 them.\n*   **adquieran un color dorado:** they acquire a golden color.\n\n**Recommendation:**\n\nI recommend **Option 1: \"Picar las cebollas finamente y sofre\u00edrlas en aceite de oliva hasta que est\u00e9n doradas.\"** It's the most natural and commonly used way to express this step in Spanish.\n\nWould you like me to provide translations for other steps in the recipe?",
    "tokens_prompt": 32,
    "tokens_completion": 379,
    "duration_s": 10.785,
    "response_time_s": 10.785,
    "energy_wh_raw": 0.095212,
    "energy_wh_net": 0.095212,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q5",
    "question_difficulty": "mixed",
    "question_task_type": "translation",
    "expected_answer_description": "Provides a grammatically correct Spanish translation of the cooking instruction.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Short translation task; tests cross\u2011lingual capability with moderate compute.",
    "tags": [
      "translation",
      "cooking",
      "short"
    ],
    "wh_per_1k_tokens": 0.231659,
    "energy_kwh_per_token": 2.32e-07,
    "g_co2": 0.033324
  },
  {
    "prompt": "Given the numbers [4, 9, 16, 25], write a Python list comprehension to compute their square roots.",
    "completion": "```python\nnumbers = [4, 9, 16, 25]\nsquare_roots = [x**0.5 for x in numbers]\nprint(square_roots)\n```\n\nThis code first defines the list of numbers. Then, it uses a list comprehension to iterate through each number `x` in the `numbers` list, calculates its square root (`x**0.5`), and adds the result to the new list `square_roots`.  Finally, it prints the resulting list of square roots. The output will be:\n\n```\n[2.0, 3.0, 4.0, 5.0]\n```\n",
    "tokens_prompt": 37,
    "tokens_completion": 144,
    "duration_s": 4.225,
    "response_time_s": 4.225,
    "energy_wh_raw": 0.035957,
    "energy_wh_net": 0.035957,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q6",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a one\u2011line Python list comprehension that applies math.sqrt or exponent 0.5 to each number.",
    "max_output_tokens_hint": 50,
    "energy_relevance": "Generates code; tests ability to produce correct syntax and moderate output.",
    "tags": [
      "python",
      "list-comprehension",
      "code"
    ],
    "wh_per_1k_tokens": 0.198657,
    "energy_kwh_per_token": 1.99e-07,
    "g_co2": 0.012585
  },
  {
    "prompt": "Write a haiku (three lines with syllable pattern 5\u20137\u20135) about the changing seasons.",
    "completion": "Green leaves turn to gold,\nCrisp air whispers winter's call,\nSnow falls, soft and slow.",
    "tokens_prompt": 31,
    "tokens_completion": 25,
    "duration_s": 0.919,
    "response_time_s": 0.918,
    "energy_wh_raw": 0.005091,
    "energy_wh_net": 0.005091,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q7",
    "question_difficulty": "mixed",
    "question_task_type": "other",
    "expected_answer_description": "Produces a three\u2011line haiku observing the 5\u20117\u20115 syllable structure and referencing seasonal change.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Creative poetry requires the model to track syllable counts; moderate compute despite short length.",
    "tags": [
      "poetry",
      "creative",
      "short"
    ],
    "wh_per_1k_tokens": 0.090911,
    "energy_kwh_per_token": 9.1e-08,
    "g_co2": 0.001782
  },
  {
    "prompt": "State the moral of Aesop\u2019s fable \u2018The Tortoise and the Hare\u2019 in one sentence.",
    "completion": "Slow and steady perseverance ultimately triumphs over hasty, overconfident effort.",
    "tokens_prompt": 30,
    "tokens_completion": 14,
    "duration_s": 0.622,
    "response_time_s": 0.622,
    "energy_wh_raw": 0.002336,
    "energy_wh_net": 0.002336,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q8",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Summarizes the moral (steady effort and perseverance often outperform careless speed).",
    "max_output_tokens_hint": 25,
    "energy_relevance": "Short summarization; tests ability to capture key lesson succinctly.",
    "tags": [
      "fable",
      "moral",
      "short"
    ],
    "wh_per_1k_tokens": 0.053091,
    "energy_kwh_per_token": 5.3e-08,
    "g_co2": 0.000818
  },
  {
    "prompt": "Explain what a binary search algorithm does in two sentences.",
    "completion": "A binary search algorithm efficiently finds a specific value within a sorted list by repeatedly dividing the search interval in half. It compares the target value to the middle element of the list; if they match, the search is complete; otherwise, the algorithm continues searching either the left or right half based on the comparison.",
    "tokens_prompt": 20,
    "tokens_completion": 62,
    "duration_s": 2.016,
    "response_time_s": 2.016,
    "energy_wh_raw": 0.017077,
    "energy_wh_net": 0.017077,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q9",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Describes that binary search repeatedly divides a sorted list to locate a target value by comparing the target to the middle element and narrowing the search interval.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Algorithm description requires concise reasoning; moderate output length.",
    "tags": [
      "computer-science",
      "algorithm",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.208256,
    "energy_kwh_per_token": 2.08e-07,
    "g_co2": 0.005977
  },
  {
    "prompt": "Given the string \u2018hello world\u2019, write pseudocode or simple code to reverse the string and briefly explain your approach.",
    "completion": "```pseudocode\n// Approach: Reverse the string by iterating through it from the end to the beginning\n// and building a new string in reverse order.\n\n// Input: string str\n// Output: reversed_string\n\nFUNCTION reverseString(str)\n  // Initialize an empty string to store the reversed string\n  reversed_string = \"\"\n\n  // Get the length of the input string\n  string_length = LENGTH(str)\n\n  // Iterate through the input string from the last character to the first\n  FOR i FROM string_length - 1 DOWNTO 0\n    // Append the character at index i to the reversed_string\n    reversed_string = reversed_string + str[i]\n  END FOR\n\n  // Return the reversed string\n  RETURN reversed_string\nEND FUNCTION\n\n\n// Example in Python:\ndef reverse_string(str):\n  reversed_string = \"\"\n  for i in range(len(str) - 1, -1, -1):\n    reversed_string += str[i]\n  return reversed_string\n\n\n# Example Usage\nstring = \"hello world\"\nreversed_string = reverse_string(string)\nprint(reversed_string) # Output: dlrow olleh\n```\n\n**Explanation:**\n\n1. **Initialization:**\n   - We start with an empty string called `reversed_string`. This will hold the reversed version of the original string.\n\n2. **Iteration:**\n   - We use a `for` loop to iterate through the original string `str` from the last character (index `string_length - 1`) down to the first character (index 0).  The `range()` function (in Python) or `DOWNTO` keyword (in pseudocode) allows us to iterate in reverse order.\n\n3. **Appending:**\n   - In each iteration of the loop, we take the character at the current index `i` from the original string (`str[i]`) and append it to the end of `reversed_string`.\n\n4. **Building the Reversed String:**\n   - As the loop continues, `reversed_string` gradually builds up, adding characters in reverse order, until it contains the completely reversed version of the original string.\n\n5. **Returning the Result:**\n   - After the loop completes, the function returns the `reversed_string`.\n\n**Alternative approaches (not demonstrated above but worth knowing):**\n\n* **Using Slicing (Python Specific):** In Python, you can easily reverse a string using string slicing: `reversed_string = str[::-1]` This creates a reversed copy of the string without the explicit loop.\n\n* **In-Place Reversal (For immutable strings):**  If you're working with a string that's *not* mutable (meaning you can't directly change its characters), you would need to create a mutable copy (like a list of characters) and reverse that list, then join the list back into a string.  This is more complex.\n",
    "tokens_prompt": 32,
    "tokens_completion": 634,
    "duration_s": 18.171,
    "response_time_s": 18.171,
    "energy_wh_raw": 0.179126,
    "energy_wh_net": 0.179126,
    "provider": "ollama",
    "model": "gemma3:4b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q10",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Provides pseudocode or a short function that iterates over the characters or uses slicing to reverse the string and explains the method.",
    "max_output_tokens_hint": 80,
    "energy_relevance": "Combines code and explanation; increases output length and tests multi\u2011modal reasoning.",
    "tags": [
      "coding",
      "string-manipulation",
      "explanation"
    ],
    "wh_per_1k_tokens": 0.268958,
    "energy_kwh_per_token": 2.69e-07,
    "g_co2": 0.062694
  }
]
