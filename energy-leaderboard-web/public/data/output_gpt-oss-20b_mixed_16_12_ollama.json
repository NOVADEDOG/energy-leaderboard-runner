[
  {
    "prompt": "Summarize the following paragraph in two sentences: Artificial intelligence is a field that has seen rapid growth in the past decade. With the advent of deep learning, machines can now perform tasks such as image recognition, language translation, and even creative writing.",
    "completion": "",
    "tokens_prompt": 118,
    "tokens_completion": 120,
    "duration_s": 3.962,
    "response_time_s": 3.962,
    "energy_wh_raw": 0.052167,
    "energy_wh_net": 0.052167,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q1",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Condenses the paragraph to two sentences mentioning AI’s rapid growth and its applications like image recognition, translation and creative tasks.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Moderate summarization; tests energy usage for condensing information.",
    "tags": [
      "summarization",
      "mixed",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.219189,
    "energy_kwh_per_token": 2.19e-07,
    "g_co2": 0.018258
  },
  {
    "prompt": "Generate a short paragraph (50–70 words) describing a fictional planet with two suns.",
    "completion": "",
    "tokens_prompt": 86,
    "tokens_completion": 290,
    "duration_s": 8.874,
    "response_time_s": 8.874,
    "energy_wh_raw": 0.121978,
    "energy_wh_net": 0.121978,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q2",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Creates a descriptive paragraph about a made‑up planet orbiting two stars, mentioning environmental features such as double shadows, long days or unique ecosystems.",
    "max_output_tokens_hint": 100,
    "energy_relevance": "Creative generation with word‑count constraint; longer output increases energy.",
    "tags": [
      "creative-writing",
      "description",
      "long-output"
    ],
    "wh_per_1k_tokens": 0.32441,
    "energy_kwh_per_token": 3.24e-07,
    "g_co2": 0.042692
  },
  {
    "prompt": "Write a JSON object with keys ‘name’, ‘age’ and ‘favorite_color’ representing a fictional character of your choice.",
    "completion": "",
    "tokens_prompt": 93,
    "tokens_completion": 164,
    "duration_s": 5.137,
    "response_time_s": 5.137,
    "energy_wh_raw": 0.069256,
    "energy_wh_net": 0.069256,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q3",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a valid JSON object with three key–value pairs, e.g., {\"name\": \"Alex\", \"age\": 28, \"favorite_color\": \"green\"}.",
    "max_output_tokens_hint": 30,
    "energy_relevance": "Structured output generation; tests the model’s ability to follow formatting instructions.",
    "tags": [
      "json",
      "structured-output",
      "short"
    ],
    "wh_per_1k_tokens": 0.269479,
    "energy_kwh_per_token": 2.69e-07,
    "g_co2": 0.02424
  },
  {
    "prompt": "Classify the following items as ‘fruit’ or ‘vegetable’: apple, carrot, banana, broccoli, tomato. Return your answer as a list of pairs [item, type].",
    "completion": "",
    "tokens_prompt": 105,
    "tokens_completion": 174,
    "duration_s": 5.498,
    "response_time_s": 5.498,
    "energy_wh_raw": 0.074664,
    "energy_wh_net": 0.074664,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q4",
    "question_difficulty": "mixed",
    "question_task_type": "classification",
    "expected_answer_description": "Produces a list of pairs indicating fruit or vegetable classifications, e.g., [[\"apple\", \"fruit\"], …].",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Requires producing a structured list and mapping categories; moderate reasoning and output length.",
    "tags": [
      "classification",
      "list",
      "structured-output"
    ],
    "wh_per_1k_tokens": 0.267613,
    "energy_kwh_per_token": 2.68e-07,
    "g_co2": 0.026132
  },
  {
    "prompt": "Translate this recipe step into Spanish: ‘Chop the onions finely and sauté them in olive oil until golden brown.’",
    "completion": "",
    "tokens_prompt": 91,
    "tokens_completion": 324,
    "duration_s": 9.822,
    "response_time_s": 9.822,
    "energy_wh_raw": 0.138273,
    "energy_wh_net": 0.138273,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q5",
    "question_difficulty": "mixed",
    "question_task_type": "translation",
    "expected_answer_description": "Provides a grammatically correct Spanish translation of the cooking instruction.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Short translation task; tests cross‑lingual capability with moderate compute.",
    "tags": [
      "translation",
      "cooking",
      "short"
    ],
    "wh_per_1k_tokens": 0.333188,
    "energy_kwh_per_token": 3.33e-07,
    "g_co2": 0.048396
  },
  {
    "prompt": "Given the numbers [4, 9, 16, 25], write a Python list comprehension to compute their square roots.",
    "completion": "",
    "tokens_prompt": 94,
    "tokens_completion": 220,
    "duration_s": 6.791,
    "response_time_s": 6.791,
    "energy_wh_raw": 0.094074,
    "energy_wh_net": 0.094074,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q6",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a one‑line Python list comprehension that applies math.sqrt or exponent 0.5 to each number.",
    "max_output_tokens_hint": 50,
    "energy_relevance": "Generates code; tests ability to produce correct syntax and moderate output.",
    "tags": [
      "python",
      "list-comprehension",
      "code"
    ],
    "wh_per_1k_tokens": 0.299599,
    "energy_kwh_per_token": 3e-07,
    "g_co2": 0.032926
  },
  {
    "prompt": "Write a haiku (three lines with syllable pattern 5–7–5) about the changing seasons.",
    "completion": "",
    "tokens_prompt": 91,
    "tokens_completion": 641,
    "duration_s": 19.503,
    "response_time_s": 19.503,
    "energy_wh_raw": 0.268289,
    "energy_wh_net": 0.268289,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q7",
    "question_difficulty": "mixed",
    "question_task_type": "other",
    "expected_answer_description": "Produces a three‑line haiku observing the 5‑7‑5 syllable structure and referencing seasonal change.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Creative poetry requires the model to track syllable counts; moderate compute despite short length.",
    "tags": [
      "poetry",
      "creative",
      "short"
    ],
    "wh_per_1k_tokens": 0.366515,
    "energy_kwh_per_token": 3.67e-07,
    "g_co2": 0.093901
  },
  {
    "prompt": "State the moral of Aesop’s fable ‘The Tortoise and the Hare’ in one sentence.",
    "completion": "",
    "tokens_prompt": 91,
    "tokens_completion": 150,
    "duration_s": 4.715,
    "response_time_s": 4.715,
    "energy_wh_raw": 0.063599,
    "energy_wh_net": 0.063599,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q8",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Summarizes the moral (steady effort and perseverance often outperform careless speed).",
    "max_output_tokens_hint": 25,
    "energy_relevance": "Short summarization; tests ability to capture key lesson succinctly.",
    "tags": [
      "fable",
      "moral",
      "short"
    ],
    "wh_per_1k_tokens": 0.263896,
    "energy_kwh_per_token": 2.64e-07,
    "g_co2": 0.02226
  },
  {
    "prompt": "Explain what a binary search algorithm does in two sentences.",
    "completion": "",
    "tokens_prompt": 79,
    "tokens_completion": 64,
    "duration_s": 2.069,
    "response_time_s": 2.069,
    "energy_wh_raw": 0.027707,
    "energy_wh_net": 0.027707,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q9",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Describes that binary search repeatedly divides a sorted list to locate a target value by comparing the target to the middle element and narrowing the search interval.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Algorithm description requires concise reasoning; moderate output length.",
    "tags": [
      "computer-science",
      "algorithm",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.193755,
    "energy_kwh_per_token": 1.94e-07,
    "g_co2": 0.009697
  },
  {
    "prompt": "Given the string ‘hello world’, write pseudocode or simple code to reverse the string and briefly explain your approach.",
    "completion": "",
    "tokens_prompt": 91,
    "tokens_completion": 191,
    "duration_s": 5.997,
    "response_time_s": 5.997,
    "energy_wh_raw": 0.080226,
    "energy_wh_net": 0.080226,
    "provider": "ollama",
    "model": "gpt-oss-20b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "AMD Radeon Graphics",
    "device_type": "amd",
    "os_name": "Linux",
    "os_version": "6.14.0-37-generic",
    "cpu_model": "AMD RYZEN AI MAX+ 395 w/ Radeon 8060S",
    "gpu_model": "AMD Radeon Graphics",
    "ram_gb": 125.1,
    "chip_architecture": "x86_64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real‑world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q10",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Provides pseudocode or a short function that iterates over the characters or uses slicing to reverse the string and explains the method.",
    "max_output_tokens_hint": 80,
    "energy_relevance": "Combines code and explanation; increases output length and tests multi‑modal reasoning.",
    "tags": [
      "coding",
      "string-manipulation",
      "explanation"
    ],
    "wh_per_1k_tokens": 0.284489,
    "energy_kwh_per_token": 2.84e-07,
    "g_co2": 0.028079
  }
]