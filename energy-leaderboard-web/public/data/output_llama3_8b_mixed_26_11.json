[
  {
    "prompt": "Summarize the following paragraph in two sentences: Artificial intelligence is a field that has seen rapid growth in the past decade. With the advent of deep learning, machines can now perform tasks such as image recognition, language translation, and even creative writing.",
    "completion": "Here is a summary of the paragraph in two sentences:\n\nArtificial intelligence has experienced significant growth over the past decade. As a result, machines are now capable of performing complex tasks like image recognition, language translation, and even generating creative content such as writing.",
    "tokens_prompt": 60,
    "tokens_completion": 52,
    "duration_s": 4.574,
    "response_time_s": 4.574,
    "energy_wh_raw": 0.023163,
    "energy_wh_net": 0.023163,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q1",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Condenses the paragraph to two sentences mentioning AI\u2019s rapid growth and its applications like image recognition, translation and creative tasks.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Moderate summarization; tests energy usage for condensing information.",
    "tags": [
      "summarization",
      "mixed",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.206812,
    "energy_kwh_per_token": 2.07e-07,
    "g_co2": 0.008107
  },
  {
    "prompt": "Generate a short paragraph (50\u201370 words) describing a fictional planet with two suns.",
    "completion": "Kaelin's Reach is a rare and wondrous world, orbiting two blazing suns that create an eternal dance of light and shadow. The dual suns, Eira and Valtor, imbue the landscape with a kaleidoscope of hues - from fiery orange to deep crimson - as they chase each other across the sky. This celestial ballet gives rise to unique flora and fauna, adapted to thrive in the perpetual twilight of Kaelin's Reach, where day and night blend into an eternal, shimmering dawn.",
    "tokens_prompt": 29,
    "tokens_completion": 108,
    "duration_s": 4.226,
    "response_time_s": 4.226,
    "energy_wh_raw": 0.036855,
    "energy_wh_net": 0.036855,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q2",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Creates a descriptive paragraph about a made\u2011up planet orbiting two stars, mentioning environmental features such as double shadows, long days or unique ecosystems.",
    "max_output_tokens_hint": 100,
    "energy_relevance": "Creative generation with word\u2011count constraint; longer output increases energy.",
    "tags": [
      "creative-writing",
      "description",
      "long-output"
    ],
    "wh_per_1k_tokens": 0.269015,
    "energy_kwh_per_token": 2.69e-07,
    "g_co2": 0.012899
  },
  {
    "prompt": "Write a JSON object with keys \u2018name\u2019, \u2018age\u2019 and \u2018favorite_color\u2019 representing a fictional character of your choice.",
    "completion": "Here is a JSON object representing the fictional character \"Luna Nightshade\":\n\n```json\n{\n  \"name\": \"Luna Nightshade\",\n  \"age\": 25,\n  \"favorite_color\": \"Midnight Blue\"\n}\n```\n\nIn this JSON object, \"Luna Nightshade\" is a young adult wizard who loves all things mysterious and magical. Her favorite color, Midnight Blue, reflects her affinity for the night sky and the magic that can be found within it.",
    "tokens_prompt": 35,
    "tokens_completion": 98,
    "duration_s": 3.801,
    "response_time_s": 3.801,
    "energy_wh_raw": 0.02961,
    "energy_wh_net": 0.02961,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q3",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a valid JSON object with three key\u2013value pairs, e.g., {\"name\": \"Alex\", \"age\": 28, \"favorite_color\": \"green\"}.",
    "max_output_tokens_hint": 30,
    "energy_relevance": "Structured output generation; tests the model\u2019s ability to follow formatting instructions.",
    "tags": [
      "json",
      "structured-output",
      "short"
    ],
    "wh_per_1k_tokens": 0.222632,
    "energy_kwh_per_token": 2.23e-07,
    "g_co2": 0.010363
  },
  {
    "prompt": "Classify the following items as \u2018fruit\u2019 or \u2018vegetable\u2019: apple, carrot, banana, broccoli, tomato. Return your answer as a list of pairs [item, type].",
    "completion": "Here is the classification:\n\n* Apple, fruit\n* Carrot, vegetable\n* Banana, fruit\n* Broccoli, vegetable\n* Tomato, fruit (note: botanically speaking, tomatoes are a type of fruit called a \"berry\", even though we commonly think of them as a vegetable in cooking and everyday language!)",
    "tokens_prompt": 47,
    "tokens_completion": 67,
    "duration_s": 2.761,
    "response_time_s": 2.761,
    "energy_wh_raw": 0.021468,
    "energy_wh_net": 0.021468,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q4",
    "question_difficulty": "mixed",
    "question_task_type": "classification",
    "expected_answer_description": "Produces a list of pairs indicating fruit or vegetable classifications, e.g., [[\"apple\", \"fruit\"], \u2026].",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Requires producing a structured list and mapping categories; moderate reasoning and output length.",
    "tags": [
      "classification",
      "list",
      "structured-output"
    ],
    "wh_per_1k_tokens": 0.188316,
    "energy_kwh_per_token": 1.88e-07,
    "g_co2": 0.007514
  },
  {
    "prompt": "Translate this recipe step into Spanish: \u2018Chop the onions finely and saut\u00e9 them in olive oil until golden brown.\u2019",
    "completion": "Here is the translation:\n\n\"Pica las cebollas finamente y sofr\u00edealas en aceite de oliva hasta que est\u00e9n doradas.\"\n\nLet me break it down for you:\n\n* \"Pica\" means \"chop\" or \"mince\"\n* \"las cebollas\" means \"the onions\"\n* \"finamente\" means \"finely\"\n* \"sor\u00edealas\" is the verb \"to saut\u00e9\" in the passive voice, meaning \"sofr\u00edealas\" (let them saut\u00e9) or \"dorarlas\" (let them brown)\n* \"en aceite de oliva\" means \"in olive oil\"\n* \"hasta que est\u00e9n doradas\" means \"until they are golden brown\"\n\nSo the whole sentence translates to: \"Chop the onions finely and let them saut\u00e9 in olive oil until they are golden brown.\"",
    "tokens_prompt": 35,
    "tokens_completion": 192,
    "duration_s": 7.527,
    "response_time_s": 7.527,
    "energy_wh_raw": 0.067354,
    "energy_wh_net": 0.067354,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q5",
    "question_difficulty": "mixed",
    "question_task_type": "translation",
    "expected_answer_description": "Provides a grammatically correct Spanish translation of the cooking instruction.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Short translation task; tests cross\u2011lingual capability with moderate compute.",
    "tags": [
      "translation",
      "cooking",
      "short"
    ],
    "wh_per_1k_tokens": 0.296714,
    "energy_kwh_per_token": 2.97e-07,
    "g_co2": 0.023574
  },
  {
    "prompt": "Given the numbers [4, 9, 16, 25], write a Python list comprehension to compute their square roots.",
    "completion": "Here is a Python list comprehension that computes the square roots of the given numbers:\n```\nnumbers = [4, 9, 16, 25]\nsqrt_numbers = [round(x ** 0.5) for x in numbers]\nprint(sqrt_numbers)  # Output: [2, 3, 4, 5]\n```\nHere's how it works:\n\n* `x ** 0.5` computes the square root of each number `x`.\n* The list comprehension `[... for x in numbers]` iterates over the original list `numbers`, applies the expression `x ** 0.5` to each element, and collects the results in a new list.\n* The `round()` function is used to round the square roots to the nearest integer.\n\nNote that this assumes you want the square roots rounded to the nearest integer. If you want the exact decimal values, simply remove the `round()` function:\n```\nnumbers = [4, 9, 16, 25]\nsqrt_numbers = [x ** 0.5 for x in numbers]\nprint(sqrt_numbers)  # Output: [2.0, 3.0, 4.0, 5.0]\n```",
    "tokens_prompt": 36,
    "tokens_completion": 251,
    "duration_s": 9.664,
    "response_time_s": 9.664,
    "energy_wh_raw": 0.087133,
    "energy_wh_net": 0.087133,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q6",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Returns a one\u2011line Python list comprehension that applies math.sqrt or exponent 0.5 to each number.",
    "max_output_tokens_hint": 50,
    "energy_relevance": "Generates code; tests ability to produce correct syntax and moderate output.",
    "tags": [
      "python",
      "list-comprehension",
      "code"
    ],
    "wh_per_1k_tokens": 0.303599,
    "energy_kwh_per_token": 3.04e-07,
    "g_co2": 0.030497
  },
  {
    "prompt": "Write a haiku (three lines with syllable pattern 5\u20137\u20135) about the changing seasons.",
    "completion": "Autumn leaves fall slow\nWinter's snowflakes gently dance\nSummer's warmth awakes",
    "tokens_prompt": 33,
    "tokens_completion": 20,
    "duration_s": 0.954,
    "response_time_s": 0.954,
    "energy_wh_raw": 0.004984,
    "energy_wh_net": 0.004984,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q7",
    "question_difficulty": "mixed",
    "question_task_type": "other",
    "expected_answer_description": "Produces a three\u2011line haiku observing the 5\u20117\u20115 syllable structure and referencing seasonal change.",
    "max_output_tokens_hint": 40,
    "energy_relevance": "Creative poetry requires the model to track syllable counts; moderate compute despite short length.",
    "tags": [
      "poetry",
      "creative",
      "short"
    ],
    "wh_per_1k_tokens": 0.094038,
    "energy_kwh_per_token": 9.4e-08,
    "g_co2": 0.001744
  },
  {
    "prompt": "State the moral of Aesop\u2019s fable \u2018The Tortoise and the Hare\u2019 in one sentence.",
    "completion": "The moral of Aesop's fable \"The Tortoise and the Hare\" is that slow and steady perseverance can ultimately lead to success, while overconfidence and laziness can result in failure.",
    "tokens_prompt": 33,
    "tokens_completion": 42,
    "duration_s": 1.842,
    "response_time_s": 1.842,
    "energy_wh_raw": 0.013899,
    "energy_wh_net": 0.013899,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q8",
    "question_difficulty": "mixed",
    "question_task_type": "summarization",
    "expected_answer_description": "Summarizes the moral (steady effort and perseverance often outperform careless speed).",
    "max_output_tokens_hint": 25,
    "energy_relevance": "Short summarization; tests ability to capture key lesson succinctly.",
    "tags": [
      "fable",
      "moral",
      "short"
    ],
    "wh_per_1k_tokens": 0.18532,
    "energy_kwh_per_token": 1.85e-07,
    "g_co2": 0.004865
  },
  {
    "prompt": "Explain what a binary search algorithm does in two sentences.",
    "completion": "A binary search algorithm is a fast and efficient method for searching through a sorted array or list of items by repeatedly dividing the search interval in half, eliminating half of the possible locations with each iteration, until the desired item is found or it is determined that the item is not present. The algorithm starts by comparing the target value to the middle element of the search range, and then recursively searches either the upper or lower half of the remaining elements based on whether the target value is greater than, less than, or equal to the middle element.",
    "tokens_prompt": 22,
    "tokens_completion": 108,
    "duration_s": 4.773,
    "response_time_s": 4.773,
    "energy_wh_raw": 0.042922,
    "energy_wh_net": 0.042922,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q9",
    "question_difficulty": "mixed",
    "question_task_type": "reasoning",
    "expected_answer_description": "Describes that binary search repeatedly divides a sorted list to locate a target value by comparing the target to the middle element and narrowing the search interval.",
    "max_output_tokens_hint": 60,
    "energy_relevance": "Algorithm description requires concise reasoning; moderate output length.",
    "tags": [
      "computer-science",
      "algorithm",
      "medium-output"
    ],
    "wh_per_1k_tokens": 0.330169,
    "energy_kwh_per_token": 3.3e-07,
    "g_co2": 0.015023
  },
  {
    "prompt": "Given the string \u2018hello world\u2019, write pseudocode or simple code to reverse the string and briefly explain your approach.",
    "completion": "Here is a simple pseudocode to reverse the string \"hello world\":\n\n```\nINPUT: original_string = \"hello world\"\nOUTPUT: reversed_string\n\nreversed_string = \"\"\n\nfor i from length(original_string) downto 1 do\n    add character at index i-1 of original_string to reversed_string\n\nprint(reversed_string)\n```\n\nExplanation:\n\n* We start by initializing an empty string `reversed_string` that will store the reversed string.\n* We then use a for loop that iterates from the length of the original string down to 1. This is because we want to process the characters in reverse order.\n* Inside the loop, we add each character at index `i-1` (because array indices start at 0) of the original string to our reversed string. We use `add character at index i-1 of original_string to reversed_string` as a placeholder for the actual operation (e.g., concatenation or assignment).\n* Finally, we print the resulting reversed string.\n\nIn code, this pseudocode could be implemented in many programming languages, such as Python:\n```python\noriginal_string = \"hello world\"\nreversed_string = \"\"\n\nfor i in range(len(original_string)-1, -1, -1):\n    reversed_string += original_string[i]\n\nprint(reversed_string)  # Output: \"dlrow olleh\"\n```\nOr in JavaScript:\n```javascript\nconst originalString = \"hello world\";\nlet reversedString = \"\";\n\nfor (let i = originalString.length - 1; i >= 0; i--) {\n    reversedString += originalString[i];\n}\n\nconsole.log(reversedString);  // Output: \"dlrow olleh\"\n```\nThe approach is to iterate through the original string in reverse order, adding each character to a new string. This effectively reverses the original string.",
    "tokens_prompt": 33,
    "tokens_completion": 375,
    "duration_s": 14.294,
    "response_time_s": 14.294,
    "energy_wh_raw": 0.128005,
    "energy_wh_net": 0.128005,
    "provider": "ollama",
    "model": "llama3:8b",
    "region": "unknown",
    "notice": null,
    "sampling_ms": 100,
    "device_name": "Apple M1 Pro Mac (MacBookPro18,3)",
    "device_type": "apple",
    "os_name": "macOS",
    "os_version": "26.1",
    "cpu_model": "Apple M1 Pro",
    "gpu_model": "Apple M1 Pro",
    "ram_gb": 16.0,
    "chip_architecture": "arm64",
    "testset_id": "ts4",
    "testset_name": "Mixed task suite (realistic workload)",
    "testset_goal": "Provide a mixture of reasoning, summarization, classification, translation and code tasks to emulate a real\u2011world workload and observe how different operations affect energy consumption.",
    "testset_notes": "This set mixes short and long prompts, structured outputs and creative tasks. Use it to test energy consumption under varied workloads. Track tokens per joule and compare models across task types, as recommended by research on tokens/J metrics.",
    "question_id": "ts4_q10",
    "question_difficulty": "mixed",
    "question_task_type": "coding",
    "expected_answer_description": "Provides pseudocode or a short function that iterates over the characters or uses slicing to reverse the string and explains the method.",
    "max_output_tokens_hint": 80,
    "energy_relevance": "Combines code and explanation; increases output length and tests multi\u2011modal reasoning.",
    "tags": [
      "coding",
      "string-manipulation",
      "explanation"
    ],
    "wh_per_1k_tokens": 0.313738,
    "energy_kwh_per_token": 3.14e-07,
    "g_co2": 0.044802
  }
]
